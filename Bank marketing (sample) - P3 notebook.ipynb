{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "################################################################################\n#\n# Licensed Materials - Property of IBM\n# (C) Copyright IBM Corp. 2019\n# US Government Users Restricted Rights - Use, duplication disclosure restricted\n# by GSA ADP Schedule Contract with IBM Corp.\n#\n################################################################################\n", 
            "cell_type": "code", 
            "execution_count": 1, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# determine if autoai_libs needs to be updated in the service pod, and if so, install the minimum required version\nimport subprocess\ntarget_package = 'autoai-libs=='\nprocess = subprocess.run('pip freeze | grep ' + target_package, stdout=subprocess.PIPE, shell=True)\noutput = process.stdout.decode('ascii')\ninstalled_vrm = ['0','0','0']\nif output.startswith(target_package):\n    version_string = output[len(target_package):-1]  # remove newline from end too\n    installed_vrm = version_string.split('.')\nminimum_vrm = ['1','10','3']\nupdate_libs = False\nfor i, val in enumerate(installed_vrm):\n    if int(val) < int(minimum_vrm[i]):\n        update_libs = True\n        break\nif update_libs:\n    module_name = '/opt/ibm/.autoAI/autoai_libs-1.10.3-1-cp36-cp36m-linux_x86_64.whl'\n    print('attempting pip install of ' + module_name)\n    process = subprocess.Popen('pip install ' + module_name, shell=True)\n    process.wait()\n    print('installation successful')", 
            "cell_type": "code", 
            "execution_count": 2, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "attempting pip install of /opt/ibm/.autoAI/autoai_libs-1.10.3-1-cp36-cp36m-linux_x86_64.whl\ninstallation successful\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "## IBM AutoAI Auto-Generated Notebook v1.10.5\n### Representing Pipeline: P3 from run b551fd60-538e-446a-8fd3-95c8bda62808\n\n**Note**: Notebook code generated using AutoAI will execute successfully.  If code is modified or reordered, there is no guarantee it will successfully execute, please read our documentation for more information https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-notebook.html .\n\nBefore modifying the pipeline or trying to re-fit the pipeline, consider:\nThe notebook converts dataframes to numpy arrays before fitting the pipeline (a current restriction of the preprocessor pipeline).\nThe known_values_list is passed by reference and populated with categorical values during fit of the preprocessing pipeline.  Delete its members before re-fitting.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 1. Set Up", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import sklearn\ntry:\n    import xgboost\nexcept:\n    print('xgboost, if needed, will be installed and imported later')\ntry:\n    import lightgbm\nexcept:\n    print('lightgbm, if needed, will be installed and imported later')\nfrom sklearn.cluster import FeatureAgglomeration\nimport numpy\nfrom numpy import nan, dtype, mean\nimport autoai_libs\nfrom autoai_libs.sklearn.custom_scorers import CustomScorers\nimport sklearn.ensemble\nfrom autoai_libs.cognito.transforms.transform_utils import TExtras, FC\nfrom autoai_libs.transformers.exportable import *\nfrom autoai_libs.utils.exportable_utils import *\nfrom sklearn.pipeline import Pipeline\nknown_values_list=[]\n", 
            "cell_type": "code", 
            "execution_count": 3, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "lightgbm, if needed, will be installed and imported later\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "### 2. Compose Pipeline", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# @hidden_cell\n#THIS CELL HAS hmac CREDENTIALS TO READ YOUR PROJECT'S CLOUD OBJECT STORAGE BUCKET.  CONSIDER DELETING THE KEYS PRIOR TO SHARING THE NOTEBOOK.\n#Load pipeline while attempting to automatically import modules and install missing packages as necessary.\nretries = 0\nsuccessful = False\nfailed_retries = 0\nwhile retries < 100 and failed_retries < 10 and not successful:\n    retries += 1\n    failed_retries += 1\n    try:\n        #\n        # composing steps for toplevel Pipeline\n        #\n        _input_metadata = {'run_uid': 'b551fd60-538e-446a-8fd3-95c8bda62808', 'pn': 'P3', 'data_source': '', 'target_label_name': 'y', 'learning_type': 'classification', 'optimization_metric': 'roc_auc', 'random_state': 33, 'cv_num_folds': 3, 'holdout_fraction': 0.1, 'data_provenance': {'input_data': [{'id': '1', 'type': 's3', 'connection': {'access_key_id': '0f60095ba3084182b099bd702375ea19', 'secret_access_key': 'f2894f220430e2fb6b1223f5c38b063659a7df1c40af9b27', 'endpoint_url': 'https://s3-api.us-geo.objectstorage.softlayer.net'}, 'location': {'type': 's3', 'bucket': 'autoai-bank-marketing-data', 'path': 'bank.csv'}}]}}\n        steps=[]\n        #\n        # composing steps for preprocessor Pipeline\n        #\n        preprocessor__input_metadata = None\n        preprocessor_steps=[]\n        #\n        # composing steps for preprocessor_features FeatureUnion\n        #\n        preprocessor_features_transformer_list=[]\n        #\n        # composing steps for preprocessor_features_categorical Pipeline\n        #\n        preprocessor_features_categorical__input_metadata = None\n        preprocessor_features_categorical_steps=[]\n        preprocessor_features_categorical_steps.append(('cat_column_selector', autoai_libs.transformers.exportable.NumpyColumnSelector(columns=[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 14, 15])))\n        preprocessor_features_categorical_steps.append(('cat_compress_strings', autoai_libs.transformers.exportable.CompressStrings(activate_flag=True, compress_type='string',\n                dtypes_list=['int_num', 'char_str', 'char_str', 'char_str', 'char_str', 'char_str', 'char_str', 'char_str', 'int_num', 'char_str', 'int_num', 'int_num', 'char_str'],\n                missing_values_reference_list=['', '-', nan, '?'],\n                misslist_list=[[], [], [], [], [], [], [], [], [], [], [], [], []])))\n        preprocessor_features_categorical_steps.append(('cat_missing_replacer', autoai_libs.transformers.exportable.NumpyReplaceMissingValues(filling_values=nan, missing_values=[])))\n        preprocessor_features_categorical_steps.append(('cat_unknown_replacer', autoai_libs.transformers.exportable.NumpyReplaceUnknownValues(filling_values=nan,\n                     filling_values_list=[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n                     known_values_list=known_values_list,\n                     missing_values_reference_list=['', '-', nan, '?'])))\n        preprocessor_features_categorical_steps.append(('boolean2float_transformer', autoai_libs.transformers.exportable.boolean2float(activate_flag=True)))\n        preprocessor_features_categorical_steps.append(('cat_imputer', autoai_libs.transformers.exportable.CatImputer(activate_flag=True, missing_values=nan,\n              sklearn_version_family='20', strategy='most_frequent')))\n        preprocessor_features_categorical_steps.append(('cat_encoder', autoai_libs.transformers.exportable.CatEncoder(activate_flag=True, categories='auto',\n              dtype=numpy.float64, encoding='ordinal',\n              handle_unknown='error', sklearn_version_family='20')))\n        preprocessor_features_categorical_steps.append(('float32_transformer', autoai_libs.transformers.exportable.float32_transform(activate_flag=True)))\n        # assembling preprocessor_features_categorical_ Pipeline\n        preprocessor_features_categorical_pipeline = sklearn.pipeline.Pipeline(steps=preprocessor_features_categorical_steps)\n        preprocessor_features_transformer_list.append(('categorical', preprocessor_features_categorical_pipeline))\n        #\n        # composing steps for preprocessor_features_numeric Pipeline\n        #\n        preprocessor_features_numeric__input_metadata = None\n        preprocessor_features_numeric_steps=[]\n        preprocessor_features_numeric_steps.append(('num_column_selector', autoai_libs.transformers.exportable.NumpyColumnSelector(columns=[5, 11, 13])))\n        preprocessor_features_numeric_steps.append(('num_floatstr2float_transformer', autoai_libs.transformers.exportable.FloatStr2Float(activate_flag=True,\n                dtypes_list=['int_num', 'int_num', 'int_num'],\n                missing_values_reference_list=[])))\n        preprocessor_features_numeric_steps.append(('num_missing_replacer', autoai_libs.transformers.exportable.NumpyReplaceMissingValues(filling_values=nan, missing_values=[])))\n        preprocessor_features_numeric_steps.append(('num_imputer', autoai_libs.transformers.exportable.NumImputer(activate_flag=True, missing_values=nan, strategy='median')))\n        preprocessor_features_numeric_steps.append(('num_scaler', autoai_libs.transformers.exportable.OptStandardScaler(num_scaler_copy=None, num_scaler_with_mean=None,\n                 num_scaler_with_std=None, use_scaler_flag=False)))\n        preprocessor_features_numeric_steps.append(('float32_transformer', autoai_libs.transformers.exportable.float32_transform(activate_flag=True)))\n        # assembling preprocessor_features_numeric_ Pipeline\n        preprocessor_features_numeric_pipeline = sklearn.pipeline.Pipeline(steps=preprocessor_features_numeric_steps)\n        preprocessor_features_transformer_list.append(('numeric', preprocessor_features_numeric_pipeline))\n        # assembling preprocessor_features_ FeatureUnion\n        preprocessor_features_pipeline = sklearn.pipeline.FeatureUnion(transformer_list=preprocessor_features_transformer_list)\n        preprocessor_steps.append(('features', preprocessor_features_pipeline))\n        preprocessor_steps.append(('permuter', autoai_libs.transformers.exportable.NumpyPermuteArray(axis=0,\n                 permutation_indices=[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 14, 15, 5, 11, 13])))\n        # assembling preprocessor_ Pipeline\n        preprocessor_pipeline = sklearn.pipeline.Pipeline(steps=preprocessor_steps)\n        steps.append(('preprocessor', preprocessor_pipeline))\n        #\n        # composing steps for cognito Pipeline\n        #\n        cognito__input_metadata = None\n        cognito_steps=[]\n        cognito_steps.append(('0', autoai_libs.cognito.transforms.transform_utils.TA2(fun = numpy.multiply, name = 'product', datatypes1 = ['intc', 'intp', 'int_', 'uint8', 'uint16', 'uint32', 'uint64', 'int8', 'int16', 'int32', 'int64', 'short', 'long', 'longlong', 'float16', 'float32', 'float64'], feat_constraints1 = [FC.is_not_categorical], datatypes2 = ['intc', 'intp', 'int_', 'uint8', 'uint16', 'uint32', 'uint64', 'int8', 'int16', 'int32', 'int64', 'short', 'long', 'longlong', 'float16', 'float32', 'float64'], feat_constraints2 = [FC.is_not_categorical], tgraph = None, apply_all = True, col_names = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome'], col_dtypes = [dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32')])))\n        cognito_steps.append(('1', autoai_libs.cognito.transforms.transform_utils.FS1(cols_ids_must_keep = range(0, 16), additional_col_count_to_keep = 15, ptype = 'classification')))\n        cognito_steps.append(('2', autoai_libs.cognito.transforms.transform_utils.TA1(fun = numpy.sqrt, name = 'sqrt', datatypes = ['numeric'], feat_constraints = [FC.is_non_negative, FC.is_not_categorical], tgraph = None, apply_all = True, col_names = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'product(age__duration)', 'product(age__pdays)', 'product(age__previous)', 'product(balance__duration)', 'product(day__duration)', 'product(duration__age)', 'product(duration__balance)', 'product(duration__day)', 'product(duration__campaign)', 'product(duration__pdays)', 'product(duration__previous)', 'product(campaign__duration)', 'product(pdays__duration)', 'product(previous__age)', 'product(previous__duration)'], col_dtypes = [dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32'), dtype('float32')])))\n        cognito_steps.append(('3', autoai_libs.cognito.transforms.transform_utils.FS1(cols_ids_must_keep = range(0, 16), additional_col_count_to_keep = 15, ptype = 'classification')))\n        # assembling cognito_ Pipeline\n        cognito_pipeline = sklearn.pipeline.Pipeline(steps=cognito_steps)\n        steps.append(('cognito', cognito_pipeline))\n        steps.append(('estimator', sklearn.ensemble.gradient_boosting.GradientBoostingClassifier(criterion='friedman_mse', init=None,\n                      learning_rate=0.1, loss='deviance', max_depth=3,\n                      max_features=None, max_leaf_nodes=None,\n                      min_impurity_decrease=0.0, min_impurity_split=None,\n                      min_samples_leaf=1, min_samples_split=2,\n                      min_weight_fraction_leaf=0.0, n_estimators=100,\n                      n_iter_no_change=None, presort='auto', random_state=33,\n                      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n                      verbose=0, warm_start=False)))\n        # assembling  Pipeline\n        pipeline = sklearn.pipeline.Pipeline(steps=steps)\n\n        successful = True\n    except Exception as e:\n        estr = str(e)\n        if estr.startswith('name ') and estr.endswith(' is not defined'):\n            try:\n                import importlib\n                module_name = estr.split(\"'\")[1]\n                module = importlib.import_module(module_name)\n                globals().update({module_name: module})\n                print('import successful for ' + module_name)\n                failed_retries -= 1\n            except Exception as import_failure:\n                print('import of ' + module_name + ' failed with: ' + str(import_failure))\n                import subprocess\n                print('attempting pip install of ' + module_name)\n                process = subprocess.Popen('pip install ' + module_name, shell=True)\n                process.wait()\n                try:\n                    print('re-attempting import of ' + module_name)\n                    module = importlib.import_module(module_name)\n                    globals().update({module_name: module})\n                    print('import successful for ' + module_name)\n                    failed_retries -= 1\n                except Exception as import_or_installation_failure:\n                    print('failure installing and/or importing ' + module_name + ' error was: ' + str(\n                        import_or_installation_failure))\n                    raise (ModuleNotFoundError('Missing package in environment for ' + module_name +\n                        '? Try import and/or pip install manually?'))\n        elif type(e) is AttributeError:\n            if 'module ' in estr and ' has no attribute ' in estr:\n                pieces = estr.split(\"'\")\n                if len(pieces) == 5:\n                    try:\n                        import importlib\n                        print('re-attempting import of ' + pieces[3] + ' from ' + pieces[1])\n                        module = importlib.import_module('.' + pieces[3], pieces[1])\n                        failed_retries -= 1\n                    except:\n                        print('failed attempt to import ' + pieces[3])\n                        raise(e)\n                else:\n                    raise(e)\n        else:\n            raise(e)\nif successful:\n    print('Pipeline successfully instantiated')\nelse:\n    raise (ModuleNotFoundError('Remaining missing imports/packages in environment? Retry cell and/or try pip install manually?'))\n", 
            "cell_type": "code", 
            "execution_count": 4, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Pipeline successfully instantiated\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n  warnings.warn(msg, category=DeprecationWarning)\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# Metadata used in retrieving data and computing metrics.  Customize as necessary for your environment.\ndata_source='replace_with_path_and_csv_filename'\ntarget_label_name = _input_metadata['target_label_name']\nlearning_type = _input_metadata['learning_type']\noptimization_metric = _input_metadata['optimization_metric']\nrandom_state = _input_metadata['random_state']\ncv_num_folds = _input_metadata['cv_num_folds']\nholdout_fraction = _input_metadata['holdout_fraction']\ndata_provenance = _input_metadata['data_provenance']\n", 
            "cell_type": "code", 
            "execution_count": 5, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "import pandas as pd\ndf = None\nif type(data_provenance) is str:\n    try:\n        df = pd.read_csv(data_provenance) # your data file name here\n    except Exception as e:\n        print(e)\nif df is None:\n    try:\n        data_location = data_provenance['input_data'][0]\n        print('data_location '+ str(data_location))\n        import boto3\n        session = boto3.session.Session()\n        cos = session.client(\n            service_name='s3',\n            aws_access_key_id=data_location['connection']['access_key_id'],\n            aws_secret_access_key=data_location['connection']['secret_access_key'],\n            endpoint_url=data_location['connection']['endpoint_url'],\n            verify=False\n        )\n        local_path = data_location['location']['path']\n        print('local_path ' + str(local_path))\n        cos.download_file(data_location['location']['bucket'],\n                     data_location['location']['path'],\n                     local_path)\n        df = pd.read_csv(local_path) # your data file name here\n    except Exception as e:\n        print(e)\nif df is None:\n    raise(ValueError('need location or credential information to read dataframe from COS'))\n", 
            "cell_type": "code", 
            "execution_count": 6, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "data_location {'id': '1', 'type': 's3', 'connection': {'access_key_id': '0f60095ba3084182b099bd702375ea19', 'secret_access_key': 'f2894f220430e2fb6b1223f5c38b063659a7df1c40af9b27', 'endpoint_url': 'https://s3-api.us-geo.objectstorage.softlayer.net'}, 'location': {'type': 's3', 'bucket': 'autoai-bank-marketing-data', 'path': 'bank.csv'}}\nlocal_path bank.csv\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "target = target_label_name # your target name here\ndf_y = df[target]\n", 
            "cell_type": "code", 
            "execution_count": 7, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "df_X = df.drop(columns=[target])", 
            "cell_type": "code", 
            "execution_count": 8, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "from sklearn.model_selection import train_test_split", 
            "cell_type": "code", 
            "execution_count": 9, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# until the problem type is available in the metadata, use the sklearn type_of_target to determine whether to stratify the holdout split\nfrom sklearn.utils.multiclass import type_of_target\nif type_of_target(df_y.values) in ['multiclass', 'binary']:\n    X, X_holdout, y, y_holdout = train_test_split(df_X.values, df_y.values, test_size=holdout_fraction, random_state=random_state, stratify=df_y.values)\nelse:\n    X, X_holdout, y, y_holdout = train_test_split(df_X.values, df_y.values, test_size=holdout_fraction, random_state=random_state)\n", 
            "cell_type": "code", 
            "execution_count": 10, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "pipeline.fit(X, y)\n", 
            "cell_type": "code", 
            "execution_count": 11, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/base.py:467: RuntimeWarning: invalid value encountered in sqrt\n  return self.fit(X, y, **fit_params).transform(X)\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "Pipeline(memory=None,\n     steps=[('preprocessor', Pipeline(memory=None,\n     steps=[('features', FeatureUnion(n_jobs=None,\n       transformer_list=[('categorical', Pipeline(memory=None,\n     steps=[('cat_column_selector', NumpyColumnSelector(columns=[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 14, 15])), ('cat_compress_strings', Comp...    subsample=1.0, tol=0.0001, validation_fraction=0.1,\n              verbose=0, warm_start=False))])"
                    }, 
                    "execution_count": 11
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "y_pred = pipeline.predict(X_holdout)\n", 
            "cell_type": "code", 
            "execution_count": 12, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/pipeline.py:451: RuntimeWarning: invalid value encountered in sqrt\n  Xt = transform.transform(Xt)\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "print(y_holdout)\nprint(y_pred)", 
            "cell_type": "code", 
            "execution_count": 13, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no'\n 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'yes' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'yes' 'no' 'no' 'no'\n 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'yes' 'no' 'no' 'no' 'no'\n 'no' 'no' 'yes' 'no' 'yes' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'yes' 'no' 'no'\n 'yes' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'yes' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no'\n 'no' 'no' 'yes' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes'\n 'yes' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'yes' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'yes' 'yes'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'yes' 'no'\n 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'yes' 'no' 'no'\n 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes'\n 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'yes' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'yes' 'no']\n['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'yes' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'yes' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes'\n 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no'\n 'no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'\n 'no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no' 'no' 'yes' 'no' 'no' 'no'\n 'no' 'no' 'no' 'yes' 'no']\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "from sklearn.metrics import get_scorer\nscorer = get_scorer(optimization_metric)\nscorer(pipeline, X_holdout, y_holdout)\n", 
            "cell_type": "code", 
            "execution_count": 14, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/pipeline.py:451: RuntimeWarning: invalid value encountered in sqrt\n  Xt = transform.transform(Xt)\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.9197678879723767"
                    }, 
                    "execution_count": 14
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "#delete CONTENTS of known_values_list before refitting, cloning or cross_validate-ing the pipeline, or previous values will be used.\nfor i in range(len(known_values_list)):\n    del known_values_list[0]", 
            "cell_type": "code", 
            "execution_count": 15, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# preprocessor should see all data for cross_validate on the remaining steps to match autoai scores\npreprocessor = pipeline.steps[0][1]\npreprocessor.fit(X)\nX_prep = preprocessor.transform(X)", 
            "cell_type": "code", 
            "execution_count": 16, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# remove preprocessor from pipeline\ndel pipeline.steps[0]", 
            "cell_type": "code", 
            "execution_count": 17, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# cross_validate on remaining steps of pipeline\nfrom sklearn.model_selection import cross_validate\ncv_results = cross_validate(pipeline, X_prep, y, scoring={optimization_metric:scorer})\nimport numpy as np\nnp.mean(cv_results['test_' + optimization_metric])\n", 
            "cell_type": "code", 
            "execution_count": 18, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/base.py:467: RuntimeWarning: invalid value encountered in sqrt\n  return self.fit(X, y, **fit_params).transform(X)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/pipeline.py:451: RuntimeWarning: invalid value encountered in sqrt\n  Xt = transform.transform(Xt)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/pipeline.py:451: RuntimeWarning: invalid value encountered in sqrt\n  Xt = transform.transform(Xt)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/base.py:467: RuntimeWarning: invalid value encountered in sqrt\n  return self.fit(X, y, **fit_params).transform(X)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/pipeline.py:451: RuntimeWarning: invalid value encountered in sqrt\n  Xt = transform.transform(Xt)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/pipeline.py:451: RuntimeWarning: invalid value encountered in sqrt\n  Xt = transform.transform(Xt)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/base.py:467: RuntimeWarning: invalid value encountered in sqrt\n  return self.fit(X, y, **fit_params).transform(X)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/pipeline.py:451: RuntimeWarning: invalid value encountered in sqrt\n  Xt = transform.transform(Xt)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/pipeline.py:451: RuntimeWarning: invalid value encountered in sqrt\n  Xt = transform.transform(Xt)\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.8955611086880445"
                    }, 
                    "execution_count": 18
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "cv_results", 
            "cell_type": "code", 
            "execution_count": 19, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n  warnings.warn(*warn_args, **warn_kwargs)\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "{'fit_time': array([0.65838051, 0.68557906, 0.68431354]),\n 'score_time': array([0.01185393, 0.01095438, 0.0108943 ]),\n 'test_roc_auc': array([0.89522293, 0.91077991, 0.88068048]),\n 'train_roc_auc': array([0.96641563, 0.95433334, 0.96146832])}"
                    }, 
                    "execution_count": 19
                }
            ], 
            "metadata": {}
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }
}